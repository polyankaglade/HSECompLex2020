{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint, PrettyPrinter\n",
    "pp = PrettyPrinter(indent=4, width=100).pprint # 3.8 sort_dicts=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Полезные ссылки:\n",
    "Главный сайт проекта: https://wordnet.princeton.edu/\n",
    "\n",
    "**ДОКУМЕНТАЦИЯ**: WordNet через nltk: http://www.nltk.org/howto/wordnet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Wall time: 317 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ищем все синсеты, в которых есть подстрока \"dog\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('dog.n.01'), Synset('frump.n.01'), Synset('dog.n.03'), Synset('cad.n.01'), Synset('frank.n.02'), Synset('pawl.n.01'), Synset('andiron.n.01'), Synset('chase.v.01')]\n",
      "Wall time: 2.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dog_synsets = wn.synsets('dog')\n",
    "print (dog_synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   Synset('dog.n.01'),\n",
      "    Synset('frump.n.01'),\n",
      "    Synset('dog.n.03'),\n",
      "    Synset('cad.n.01'),\n",
      "    Synset('frank.n.02'),\n",
      "    Synset('pawl.n.01'),\n",
      "    Synset('andiron.n.01'),\n",
      "    Synset('chase.v.01')]\n"
     ]
    }
   ],
   "source": [
    "pp(dog_synsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно уточнить, какие именно части речи нас интересуют. Возможные варианты: NOUN, ADJ, ADV, VERB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   Synset('dog.n.01'),\n",
      "    Synset('frump.n.01'),\n",
      "    Synset('dog.n.03'),\n",
      "    Synset('cad.n.01'),\n",
      "    Synset('frank.n.02'),\n",
      "    Synset('pawl.n.01'),\n",
      "    Synset('andiron.n.01')]\n"
     ]
    }
   ],
   "source": [
    "dog_noun_synsets = wn.synsets('dog', pos=wn.NOUN)\n",
    "pp (dog_noun_synsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доступ ко всем синсетам и ко всем словам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117659\n",
      "13767\n",
      "21479\n",
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print (len(list(wn.all_synsets())))\n",
    "print (len(list(wn.all_synsets('v'))))\n",
    "print (len(list(wn.all_lemma_names('a'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Про синсет мы можем узнать: его имя (ID синсета), определение, ID относящихся к нему лемм, сами леммы; посмотреть примеры (если они есть) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   'dog.n.01',\n",
      "    'a member of the genus Canis (probably descended from the common wolf) that has been '\n",
      "    'domesticated by man since prehistoric times; occurs in many breeds',\n",
      "    [Lemma('dog.n.01.dog'), Lemma('dog.n.01.domestic_dog'), Lemma('dog.n.01.Canis_familiaris')],\n",
      "    ['dog', 'domestic_dog', 'Canis_familiaris'],\n",
      "    ['the dog barked all night']]\n"
     ]
    }
   ],
   "source": [
    "dog_exemplar = wn.synset('dog.n.01')\n",
    "pp ([dog_exemplar.name(), dog_exemplar.definition(), dog_exemplar.lemmas(), dog_exemplar.lemma_names(),\n",
    "       dog_exemplar.examples()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Отношения между синсетами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('basenji.n.01'), Synset('corgi.n.01'), Synset('cur.n.01'), Synset('dalmatian.n.02'),\n",
      " Synset('great_pyrenees.n.01'), Synset('griffon.n.02'), Synset('hunting_dog.n.01'),\n",
      " Synset('lapdog.n.01'), Synset('leonberg.n.01'), Synset('mexican_hairless.n.01'),\n",
      " Synset('newfoundland.n.01'), Synset('pooch.n.01'), Synset('poodle.n.01'), Synset('pug.n.01'),\n",
      " Synset('puppy.n.01'), Synset('spitz.n.01'), Synset('toy_dog.n.01'), Synset('working_dog.n.01')]\n",
      "[Synset('canine.n.02'), Synset('domestic_animal.n.01')]\n",
      "[Synset('entity.n.01')]\n",
      "[Synset('canis.n.01'), Synset('pack.n.06')]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "pprint (dog_exemplar.hyponyms(), compact=True, width=100)\n",
    "print (dog_exemplar.hypernyms())\n",
    "print (dog_exemplar.root_hypernyms())\n",
    "print (dog_exemplar.member_holonyms())\n",
    "print (dog_exemplar.member_meronyms())\n",
    "print (dog_exemplar.similar_tos())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ближайший общий гипероним"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('organism.n.01')]\n"
     ]
    }
   ],
   "source": [
    "print(wn.synset('person.n.01').lowest_common_hypernyms(wn.synset('dog.n.01')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расстояние между синсетами: <br>\n",
    "path_similarity - оценивает расстояние по кратчайшему пути между синсетами. <br>\n",
    "Значение - от 0 до 1, где 1 - максимальная степень близости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "0.1\n",
      "1.0\n",
      "Wall time: 4.54 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(wn.synset('dog.n.01').path_similarity(wn.synset('cat.n.01')))\n",
    "print(wn.synset('person.n.01').path_similarity(wn.synset('cat.n.01')))\n",
    "print(wn.synset('dog.n.01').path_similarity(wn.synset('dog.n.01')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Деривационные отношения и отношение антонимии определены только для лемм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personal\n",
      "Pertainyms: []\n",
      "Antonyms: []\n",
      "Derivationally related forms: []\n",
      "\n",
      "personal\n",
      "Pertainyms: []\n",
      "Antonyms: [Lemma('impersonal.a.01.impersonal')]\n",
      "Derivationally related forms: []\n",
      "\n",
      "personal\n",
      "Pertainyms: []\n",
      "Antonyms: []\n",
      "Derivationally related forms: []\n",
      "\n",
      "personal\n",
      "Pertainyms: [Lemma('personality.n.01.personality')]\n",
      "Antonyms: []\n",
      "Derivationally related forms: [Lemma('personality.n.01.personality')]\n",
      "\n",
      "personal\n",
      "Pertainyms: []\n",
      "Antonyms: []\n",
      "Derivationally related forms: []\n",
      "\n",
      "personal\n",
      "Pertainyms: [Lemma('person.n.03.person')]\n",
      "Antonyms: []\n",
      "Derivationally related forms: []\n",
      "\n",
      "Wall time: 4.68 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for lemma in wn.lemmas('personal'):\n",
    "    print (lemma.name())\n",
    "    print ('Pertainyms:', lemma.pertainyms())\n",
    "    print ('Antonyms:', lemma.antonyms())\n",
    "    print ('Derivationally related forms:', lemma.derivationally_related_forms())\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiWordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://compling.hss.ntu.edu.sg/omw/ <br>\n",
    "Условные обозначения языков: коды ISO-639"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['als',\n",
       "  'arb',\n",
       "  'bul',\n",
       "  'cat',\n",
       "  'cmn',\n",
       "  'dan',\n",
       "  'ell',\n",
       "  'eng',\n",
       "  'eus',\n",
       "  'fas',\n",
       "  'fin',\n",
       "  'fra',\n",
       "  'glg',\n",
       "  'heb',\n",
       "  'hrv',\n",
       "  'ind',\n",
       "  'ita',\n",
       "  'jpn',\n",
       "  'nld',\n",
       "  'nno',\n",
       "  'nob',\n",
       "  'pol',\n",
       "  'por',\n",
       "  'qcn',\n",
       "  'slv',\n",
       "  'spa',\n",
       "  'swe',\n",
       "  'tha',\n",
       "  'zsm'],\n",
       " 29)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(wn.langs()), len(wn.langs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['canis_familiaris', 'chien']\n",
      "['Canis_lupus_familiaris', 'domaći_pas', 'pas']\n",
      "['イヌ', 'ドッグ', '洋犬', '犬', '飼犬', '飼い犬']\n",
      "Wall time: 1.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print (dog_exemplar.lemma_names('fra'))\n",
    "print (dog_exemplar.lemma_names('hrv'))\n",
    "print (dog_exemplar.lemma_names('jpn'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# FrameNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Главный сайт проекта: https://framenet2.icsi.berkeley.edu\n",
    "\n",
    "**ДОКУМЕНТАЦИЯ**: FrameNet через NLTK: http://www.nltk.org/howto/framenet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package framenet_v17 to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package framenet_v17 is already up-to-date!\n",
      "Wall time: 3.94 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "nltk.download('framenet_v17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import framenet as fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все фреймы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<frame ID=2031 name=Abandonment>, <frame ID=262 name=Abounding_with>, ...] 1221\n",
      "Wall time: 2.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print (fn.frames(), len(fn.frames()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все фреймы, в которых есть подстрока 'event':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change_event_duration\n",
      "Change_event_time\n",
      "Desirable_event\n",
      "Historic_event\n",
      "Locale_by_event\n",
      "Prevent_or_allow_possession\n",
      "Preventing_or_letting\n",
      "Required_event\n",
      "Social_event\n",
      "Social_event_collective\n",
      "Social_event_individuals\n"
     ]
    }
   ],
   "source": [
    "for frame in fn.frames('event'):\n",
    "    print (frame.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<lu ID=16601 name=(can't) help.v>, <lu ID=14632 name=(in/out of) line.n>, ...] 13572\n"
     ]
    }
   ],
   "source": [
    "print (fn.lus(), len(fn.lus()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый фрейм - это словарь. Заглянем внутрь фрейма Historic_event:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame (1908): Historic_event\n",
      "\n",
      "[URL] https://framenet2.icsi.berkeley.edu/fnReports/data/frame/Historic_event.xml\n",
      "\n",
      "[definition]\n",
      "  In the course of history, an Event or Entity is taken to have\n",
      "  importance or significance.  'Throughout the campaign activists\n",
      "  have made financial history as one by one major corporations have\n",
      "  yielded to protester power'  'The conference was historic for\n",
      "  Atlanta's growth as a city.'  'Many of the historic sites offer\n",
      "  additional outdoor recreation activities.'  'The James River is\n",
      "  arguably the most historic river in the country and one of the\n",
      "  most important rivers in the Southeast.'  'Take in the history,\n",
      "  the sawdust-covered floors, and the legendary backroom where the\n",
      "  ale flowed during Prohibition.'\n",
      "\n",
      "[semTypes] 0 semantic types\n",
      "\n",
      "[frameRelations] 3 frame relations\n",
      "  <Parent=Eventive_affecting -- Inheritance -> Child=Historic_event>\n",
      "  <Complex=Individual_history -- Subframe -> Component=Historic_event>\n",
      "  <Parent=Importance -- Using -> Child=Historic_event>\n",
      "\n",
      "[lexUnit] 3 lexical units\n",
      "  historic [entity].a (15178), historic.a (14182), make\n",
      "  history.idio (14183)\n",
      "\n",
      "\n",
      "[FE] 8 frame elements\n",
      "            Core: Entity (11421), Event (11417)\n",
      "      Peripheral: Domain (11427), Manner (11422), Place (11418), Time (11419)\n",
      "  Extra-Thematic: Degree (13000), Explanation (11420)\n",
      "\n",
      "[FEcoreSets] 1 frame element core sets\n",
      "  Event, Entity\n",
      "\n"
     ]
    }
   ],
   "source": [
    "frame_HistEvent = fn.frame('Historic_event')\n",
    "print (frame_HistEvent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FE и lexUnit - тоже словари:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Event] frame element (11417): Event\n",
      "    of Historic_event(1908)\n",
      "[definition]\n",
      "  This FE identifies the event which occurs to create history.\n",
      "[abbrev] Evnt\n",
      "[coreType] Core\n",
      "[requiresFE] <None>\n",
      "[excludesFE] <None>\n",
      "[semType] \n",
      "  State_of_affairs(177)\n",
      "\n",
      "[Place] frame element (11418): Place\n",
      "    of Historic_event(1908)\n",
      "[definition]\n",
      "  This FE identifies where the event takes place.\n",
      "[abbrev] Place\n",
      "[coreType] Peripheral\n",
      "[requiresFE] <None>\n",
      "[excludesFE] <None>\n",
      "[semType] \n",
      "  Locative_relation(182)\n",
      "\n",
      "[Time] frame element (11419): Time\n",
      "    of Historic_event(1908)\n",
      "[definition]\n",
      "  This FE identifies the time when the event occurs.\n",
      "[abbrev] Time\n",
      "[coreType] Peripheral\n",
      "[requiresFE] <None>\n",
      "[excludesFE] <None>\n",
      "[semType] \n",
      "  Time(141)\n",
      "\n",
      "[Explanation] frame element (11420): Explanation\n",
      "    of Historic_event(1908)\n",
      "[definition]\n",
      "  This FE identifies the Explanation for which an event occurs.\n",
      "[abbrev] Exp\n",
      "[coreType] Extra-Thematic\n",
      "[requiresFE] <None>\n",
      "[excludesFE] <None>\n",
      "[semType] \n",
      "  State_of_affairs(177)\n",
      "\n",
      "[Entity] frame element (11421): Entity\n",
      "    of Historic_event(1908)\n",
      "[definition]\n",
      "  This FE identifies the entity, concrete or abstract.\n",
      "[abbrev] Ent\n",
      "[coreType] Core\n",
      "[requiresFE] <None>\n",
      "[excludesFE] <None>\n",
      "[semType] <None>\n",
      "\n",
      "[Manner] frame element (11422): Manner\n",
      "    of Historic_event(1908)\n",
      "[definition]\n",
      "  Any description of the event which is not covered by more\n",
      "  specific FEs, including secondary effects (quietly, loudly) and\n",
      "  general descriptions comparing events (the same way).\n",
      "[abbrev] Man\n",
      "[coreType] Peripheral\n",
      "[requiresFE] <None>\n",
      "[excludesFE] <None>\n",
      "[semType] <None>\n",
      "\n",
      "[Domain] frame element (11427): Domain\n",
      "    of Historic_event(1908)\n",
      "[definition]\n",
      "  The Domain is (a characterization of) the type of event that is\n",
      "  part of the Event's history.  'Throughout the campaign activists\n",
      "  have made financial history as one by one major corporations have\n",
      "  yielded to protester power'\n",
      "[abbrev] dom\n",
      "[coreType] Peripheral\n",
      "[requiresFE] <None>\n",
      "[excludesFE] <None>\n",
      "[semType] <None>\n",
      "\n",
      "[Degree] frame element (13000): Degree\n",
      "    of Historic_event(1908)\n",
      "[definition]\n",
      "  This frame element selects some gradable attribute and modifies\n",
      "  the expected value for it.\n",
      "[abbrev] Deg\n",
      "[coreType] Extra-Thematic\n",
      "[requiresFE] <None>\n",
      "[excludesFE] <None>\n",
      "[semType] <None>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (frame_HistEvent.FE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Способы обратиться к элементам фрейма (FE) \\[потому что это словарь\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This FE identifies the event which occurs to create history.\n",
      "This FE identifies the event which occurs to create history.\n"
     ]
    }
   ],
   "source": [
    "print (frame_HistEvent.FE.Event.definition)\n",
    "print (frame_HistEvent['FE']['Event']['definition'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В словарях лексических юнитов скрываются размеченные примеры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lexical unit (14182): historic.a\n",
      "\n",
      "[definition]\n",
      "  COD: famous or important in history, or potentially so.\n",
      "\n",
      "[frame] Historic_event(1908)\n",
      "\n",
      "[POS] A\n",
      "\n",
      "[status] Finished_Initial\n",
      "\n",
      "[lexemes] historic/A\n",
      "\n",
      "[semTypes] 0 semantic types\n",
      "\n",
      "[URL] https://framenet2.icsi.berkeley.edu/fnReports/data/lu/lu14182.xml\n",
      "\n",
      "[subCorpus] 8 subcorpora\n",
      "  01-T-Wmoment,victory,opportunity-(1), 03-NP-VP-T-(1),\n",
      "  04-T-NP-(1), 05-AVP-T-(1), 06-T-AVP-(1), manually-added,\n",
      "  other-matched-(1), other-unmatched-(1)\n",
      "\n",
      "[exemplars] 17 sentences across all subcorpora\n",
      "\n"
     ]
    }
   ],
   "source": [
    "historic = frame_HistEvent.lexUnit['historic.a']\n",
    "# то же самое (по ID):\n",
    "# historic = fn.lu(14182))\n",
    "print (historic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exemplar sentence (1454496):\n",
      "[corpID] 111\n",
      "[docID] 421\n",
      "[paragNo] 7518\n",
      "[sentNo] 1\n",
      "[aPos] 28944963\n",
      "\n",
      "[LU] (14182) historic.a in Historic_event\n",
      "\n",
      "[frame] (1908) Historic_event\n",
      "\n",
      "[annotationSet] 2 annotation sets\n",
      "\n",
      "[POS] 27 tags\n",
      "\n",
      "[POS_tagset] PENN\n",
      "\n",
      "[GF] 2 relations\n",
      "\n",
      "[PT] 2 phrases\n",
      "\n",
      "[text] + [Target] + [FE]\n",
      "\n",
      "Researchers expected to find six out of ten people could recall \n",
      "                                                                \n",
      "                                                                \n",
      " \n",
      "Lady Thatcher 's historic resignation moment in vivid detail by \n",
      "---------------- ******** ------------------\n",
      "Entity                    Event             \n",
      " \n",
      "retaining a long-lasting ` flashbulb \" memory .\n",
      " \n",
      " \n",
      " \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (historic.exemplars[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практические задания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите все фреймы, в число ядерных (Core) элементов которых входит участник с ролью начальной точки перемещения (Source)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите все ядерные элементы фрейма Removing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите 5 примеров употребления лексемы take.v из фрейма Removing (с разметкой)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Что еще можно делать семантическими сетями?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### считать схожесть слов разными способами\n",
    "\n",
    "подробнее: https://www.nltk.org/howto/wordnet.html#similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog = wn.synset('dog.n.01')\n",
    "cat = wn.synset('cat.n.01')\n",
    "\n",
    "collar = wn.synset('collar.n.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "2.0281482472922856\n",
      "0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "print(dog.path_similarity(cat)) # [0,1]\n",
    "print(dog.lch_similarity(cat)) \n",
    "print(dog.wup_similarity(cat)) # [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "1.3350010667323402\n",
      "0.47058823529411764\n"
     ]
    }
   ],
   "source": [
    "print(dog.path_similarity(collar))\n",
    "print(dog.lch_similarity(collar)) \n",
    "print(dog.wup_similarity(collar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### лемматизировать\n",
    "\n",
    "[оригинальный текст](https://www.machinelearningplus.com/nlp/lemmatization-examples-python/)\n",
    "\n",
    "В NLTK уже есть готовый лемматизатор на основе WordNet'a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bat\n",
      "are\n",
      "foot\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize(\"bats\"))\n",
    "print(lemmatizer.lemmatize(\"are\"))\n",
    "print(lemmatizer.lemmatize(\"feet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'striped', 'bats', 'are', 'hanging', 'on', 'their', 'feet', 'for', 'best']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The striped bats are hanging on their feet for best\"\n",
    "word_list = nltk.word_tokenize(sentence)\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The striped bat are hanging on their foot for best\n"
     ]
    }
   ],
   "source": [
    "lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "print(lemmatized_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, не вре слова лемматизировались так, как можно было ожидать. Почему? Потому что, как мы уже обсуждали, Иногда одно и то же слово может иметь несколько лемм в зависимости от значения / контекста. Эту проблему можно решить, передав лемматизатору POS тег:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strip\n",
      "stripe\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize(\"stripes\", 'v'))  \n",
    "print(lemmatizer.lemmatize(\"stripes\", 'n'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для получения частей речи можно использовать NLTK POS-tagger.\n",
    "\n",
    "**NB**: набор тегов WordNet'a отличается от стандартых nltk POS тегов. Для преобразования одних в другие можно сделать так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wn.ADJ,\n",
    "                \"N\": wn.NOUN,\n",
    "                \"V\": wn.VERB,\n",
    "                \"R\": wn.ADV}\n",
    "    return tag_dict.get(tag, wn.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foot\n"
     ]
    }
   ],
   "source": [
    "word = 'feet'\n",
    "print(lemmatizer.lemmatize(word, get_wordnet_pos(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'strip', 'bat', 'be', 'hang', 'on', 'their', 'foot', 'for', 'best']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The striped bats are hanging on their feet for best\"\n",
    "print([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(sentence)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word-sense disambiguation (WSD)\n",
    "\n",
    "подробнее [WordNet: Word Relations,Senses, and Disambiguation (pdf)](https://web.stanford.edu/~jurafsky/slp3/C.pdf)\n",
    "\n",
    "* The Lesk algorithm chooses the sense whose dictionary definition shares the most words with the target word’s neighborhood.\n",
    "* Graph-based algorithms view the thesaurus as a graph and choose the sense that is most central in some way.\n",
    "\n",
    "\n",
    "Lesk через NLKT: http://www.nltk.org/howto/wsd.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.wsd import lesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   'savings_bank.n.02',\n",
      "    'a container (usually with a slot in the top) for keeping money at home',\n",
      "    ['savings_bank', 'coin_bank', 'money_box', 'bank'],\n",
      "    ['the coin bank was empty']]\n"
     ]
    }
   ],
   "source": [
    "sent = ['I', 'keep', 'my', 'coin', 'in', 'a', 'piggy', 'bank', '.']\n",
    "bank_meaning = lesk(sent, 'bank', 'n')\n",
    "pp ([bank_meaning.name(), bank_meaning.definition(), bank_meaning.lemma_names(),\n",
    "       bank_meaning.examples()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   'bank.n.07',\n",
      "    'a slope in the turn of a road or track; the outside is higher than the inside in order to '\n",
      "    'reduce the effects of centrifugal force',\n",
      "    ['bank', 'cant', 'camber'],\n",
      "    []]\n"
     ]
    }
   ],
   "source": [
    "sent = 'We went to the river and I jumped in the water from the bank .'.split()\n",
    "bank_meaning = lesk(sent, 'bank')\n",
    "pp ([bank_meaning.name(), bank_meaning.definition(), bank_meaning.lemma_names(),\n",
    "       bank_meaning.examples()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   'deposit.v.02',\n",
      "    'put into a bank account',\n",
      "    ['deposit', 'bank'],\n",
      "    ['She deposits her paycheck every month']]\n"
     ]
    }
   ],
   "source": [
    "sent = 'Did you make a deposit to our bank account ?'.split()\n",
    "bank_meaning = lesk(sent, 'bank')\n",
    "pp ([bank_meaning.name(), bank_meaning.definition(), bank_meaning.lemma_names(),\n",
    "       bank_meaning.examples()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   'bank.n.06',\n",
      "    'the funds held by a gambling house or the dealer in some gambling games',\n",
      "    ['bank'],\n",
      "    ['he tried to break the bank at Monte Carlo']]\n"
     ]
    }
   ],
   "source": [
    "sent = \"How much is the dealer 's gambling bank right now ?\".split()\n",
    "bank_meaning = lesk(sent, 'bank')\n",
    "pp ([bank_meaning.name(), bank_meaning.definition(), bank_meaning.lemma_names(),\n",
    "       bank_meaning.examples()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Дарья Попова, Дарья Рыжова, ред. Анна Полянская, 2020, НИУ ВШЭ*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
